* 单词

messageQueue : 消息队列  <br>
  message /'mɛsɪdʒ/ : 消息  <br>
  queue /kju/ : 队列
  
  Partition /pɑr'tɪʃən/ : 分区
  
  topic /'tɒpɪk/ : 主题（等于theme）；题目；一般规则；总论
  
  broker /'brəʊkə/ : 经纪人，掮客,也可以认为是服务器
  
  Producer /prə'dʊsɚ/ : 生产者
  
  Consumer /kən'sumɚ/ : 消费者
  
  Cluster  /'klʌstɚ/ : 群；簇；丛；串
  
  segment /'sɛɡmənt/  : 段,线条
  
  offset : 偏移量
  
  
  

### 1 为什么使用消息队列? 消息队列的作用是什么?

消息系统的核心作用就是三点：解耦，异步和并行

* 传统系统之间的耦合性太强,一但一台服务器挂掉,整个集群都无法运行.

* 并行
  
  可以使多个服务器同时处理消息.
  
  *扩展 :*
  
  并行与并发的区别:<br>
  **并行(parallel):**
  指在同一时刻，有多条指令在多个处理器上同时执行。就好像两个人各拿一把铁锨在挖坑，一小时后，每人一个大坑。所以无论从微观还是从宏观来   看，二者都是一起执行的。
  
  ![并行](https://github.com/bigDataHell/Kangaroo-/blob/master/images/%E5%B9%B6%E5%8F%91.png)
  

  **并发(concurrency)：**
  指在同一时刻只能有一条指令执行，但多个进程指令被快速的轮换执行，使得在宏观上具有多个进程同时执行的效果，但在微观上并不是同时执   行的，只是把时间分成若干段，使多个进程快速交替的执行。这就好像两个人用同一把铁锨，轮流挖坑，一小时后，两个人各挖一个小一点的坑，要想挖两个大一点得   坑，一定会用两个小时。
  
  ![并发](https://github.com/bigDataHell/Kangaroo-/blob/master/images/%E5%B9%B6%E8%A1%8C.png)

  **并行包括并发**
  
* 冗余

有时在处理数据的时候处理过程会失败。除非数据被持久化，否则将永远丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。在被许多消息队列所采用的"插入-获取-删除"范式中，在把一个消息从队列中删除之前，需要你的处理过程明确的指出该消息已经被处理完毕，确保你的数据被安全的保存直到你使用完毕。
  
* 异步通信

很多时候，你不想也不需要立即处理消息。消息队列提供了异步处理机制，允许你把一个消息放入队列，但并不立即处理它。你想向队列中放入多少消息就放多少，然后在你乐意的时候再去处理它们。

* 缓冲

在任何重要的系统中，都会有需要不同的处理时间的元素。例如,加载一张图片比应用过滤器花费更少的时间。消息队列通过一个缓冲层来帮助任务最高效率的执行--写入队列的处理会尽可能的快速，而不受从队列读的预备处理的约束。该缓冲有助于控制和优化数据流经过系统的速度




### 2 Kafka的Topic和分区内部是如何存储的,有什么特点?

Topic是把数据分别存储到不同的分区中,也就是存放到不同的服务器中.

分区内部的数据是存放在多个文件中的,每个分区都有一定数量的.inde文件和.log文件,其中.index和.log文件,这两个文件组成一个`segment` 段,
这个段就存储着分区内的一部分数据,默认是1G.


### 3 与传统的消息系统相比,Kafka的消费模型有什么优点?

  kafka的消费模型是分布式的
  
  
### 4 Kafka如何实现分布式的数据存储与数据读取?

在Kafka文件存储中，同一个 topic下有多个不同partition，每个 partition 为一个目录,拥有自己的分区id,topic产生的数据分成多分存储在分区中,
每个分区都对应一台服务器,这样就把数据存放在了不同的服务器上,实现了分布式的数据存储.




### 5 Kafka为什么比RocketMQ支持的单机Partition要少?

### 6 为什么需要分区?也就是说主题只有一个分区,难道不行吗?


  如果只有一个分区,那么我们的topic产生的所有数据都会存放到一个broker中,一台服务器的内存是有限的,当数据足够大时,会造成服务器的内存不足,
就会影响到我们的服务,所以我们需要分区,把数据分成多分存储在不同的broker中,以减轻服务器的存储压力.

  同时这也会造成一个问题: 如果将数据分区存储,如果其中一台服务器挂掉,则会造成这部分数据不可用.<br>
解决方法: 对数据进行备份,也就是副本机制,将同一份数据备份,放到不同的服务器上.


### 7 日志为什么需要分段?

Kafka中的数据是以日志的形式存储的,Kafka作为消息中间件,只负责消息的临时存储,并不是永久存储,需要删除过期的数据.<br>
如果把所有的数据都存放在同一个文件,则删除过期的数据会很麻烦. <br>
因为文件有日期属性,删除过期的数据只需要根据文件的日期属性删除就行.

补充一下删除数据的两种方式:

        1 按照日期删除,如果只存储7天的日志,超过7天的则删除
        2 按照行数删除/按照文件的大小
    

### 8 Kafka是依靠什么机制保持高可靠的,高可用?

依靠副本机制

kafka中的多个服务端节点会对其他服务端节点的主题分区的log文件进行复制.

当集群中一个服务节点故障之后,这个故障的的服务器节点的所有请求都会被转移到其他正常的节点

kafka中的每个主题分区都有一个主副本(leader)和0个或多个副本,副本会同步主副本中的数据,当主副本不可用时,kafka会选择一个副本接替工作,
但并不是所有的副本都能担任主副本,需要满足两个条件:
  * 该副本保持和zookeeper的通信.
  * 该副本中同步主副本中的数据是最多的.

### 9 消息队列如何保证消息幂等?

### 10 让你自己设计个消息队列,你会怎么设计,会考虑那些方面?





