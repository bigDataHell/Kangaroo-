* 单词

messageQueue : 消息队列  <br>
  message /'mɛsɪdʒ/ : 消息  <br>
  queue /kju/ : 队列
  
  Partition /pɑr'tɪʃən/ : 分区
  
  topic /'tɒpɪk/ : 主题（等于theme）；题目；一般规则；总论
  
  broker /'brəʊkə/ : 经纪人，掮客,也可以认为是服务器
  
  Producer /prə'dʊsɚ/ : 生产者
  
  Consumer /kən'sumɚ/ : 消费者
  
  Cluster  /'klʌstɚ/ : 群；簇；丛；串
  
  segment /'sɛɡmənt/  : 段,线条
  
  offset : 偏移量
  
  
  

### 1 为什么使用消息队列? 消息队列的作用是什么?

你需要使用消息队列时，首先需要考虑它的必要性。可以使用mq的场景有很多，最常用的几种，是做业务解耦/最终一致性/广播/错峰流控等。反之，如果需要强一致性，关注业务逻辑的处理结果，则RPC显得更为合适。

* 解耦

解耦是消息队列要解决的最本质问题。所谓解耦，简单点讲就是一个事务，只关心核心的流程。而需要依赖其他系统但不那么重要的事情，有通知即可，无需等待结果。换句话说，基于消息的模型，关心的是“通知”，而非“处理”。

对于我们的订单系统，订单最终支付成功之后可能需要给用户发送短信积分什么的，但其实这已经不是我们系统的核心流程了。如果外部系统速度偏慢（比如短信网关速度不好），那么主流程的时间会加长很多，用户肯定不希望点击支付过好几分钟才看到结果。那么我们只需要通知短信系统“我们支付成功了”，不一定非要等待它处理完成。

* 广播

消息队列的基本功能之一是进行广播。如果没有消息队列，每当一个新的业务方接入，我们都要联调一次新接口。有了消息队列，我们只需要关心消息是否送达了队列，至于谁希望订阅，是下游的事情，无疑极大地减少了开发和联调的工作量。
比如本文开始提到的产品中心发布产品变更的消息，以及景点库很多去重更新的消息，可能“关心”方有很多个，但产品中心和景点库只需要发布变更消息即可，谁关心谁接入。

* 错峰与流控

试想上下游对于事情的处理能力是不同的。比如，Web前端每秒承受上千万的请求，并不是什么神奇的事情，只需要加多一点机器，再搭建一些LVS负载均衡设备和Nginx等即可。但数据库的处理能力却十分有限，即使使用SSD加分库分表，单机的处理能力仍然在万级。由于成本的考虑，我们不能奢求数据库的机器数量追上前端。

这种问题同样存在于系统和系统之间，如短信系统可能由于短板效应，速度卡在网关上（每秒几百次请求），跟前端的并发量不是一个数量级。但用户晚上个半分钟左右收到短信，一般是不会有太大问题的。如果没有消息队列，两个系统之间通过协商、滑动窗口等复杂的方案也不是说不能实现。

但系统复杂性指数级增长，势必在上游或者下游做存储，并且要处理定时、拥塞等一系列问题。而且每当有处理能力有差距的时候，都需要单独开发一套逻辑来维护这套逻辑。所以，利用中间系统转储两个系统的通信内容，并在下游系统有能力处理这些消息的时候，再处理这些消息，是一套相对较通用的方式。
消息系统的核心作用就是三点：解耦，异步和并行


* 并行
  
可以使用不同的服务器处理相同的消息,提高数据的处理效率,
也可以将消息分为不同的模块交给不同的服务器处理,使多个服务器共同处理一个请求.
  
* 冗余

有时在处理数据的时候处理过程会失败。除非数据被持久化，否则将永远丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。在被许多消息队列所采用的"插入-获取-删除"范式中，在把一个消息从队列中删除之前，需要你的处理过程明确的指出该消息已经被处理完毕，确保你的数据被安全的保存直到你使用完毕。
  
* 异步通信

很多时候，你不想也不需要立即处理消息。消息队列提供了异步处理机制，允许你把一个消息放入队列，但并不立即处理它。你想向队列中放入多少消息就放多少，然后在你乐意的时候再去处理它们。

  
  *扩展 :*
  
  并行与并发的区别:<br>
  **并行(parallel):**
  指在同一时刻，有多条指令在多个处理器上同时执行。就好像两个人各拿一把铁锨在挖坑，一小时后，每人一个大坑。所以无论从微观还是从宏观来   看，二者都是一起执行的。
  
  ![并行](https://github.com/bigDataHell/Kangaroo-/blob/master/images/%E5%B9%B6%E5%8F%91.png)
  

  **并发(concurrency)：**
  指在同一时刻只能有一条指令执行，但多个进程指令被快速的轮换执行，使得在宏观上具有多个进程同时执行的效果，但在微观上并不是同时执   行的，只是把时间分成若干段，使多个进程快速交替的执行。这就好像两个人用同一把铁锨，轮流挖坑，一小时后，两个人各挖一个小一点的坑，要想挖两个大一点得   坑，一定会用两个小时。
  
  ![并发](https://github.com/bigDataHell/Kangaroo-/blob/master/images/%E5%B9%B6%E8%A1%8C.png)


  





### 2 Kafka的Topic和分区内部是如何存储的,有什么特点?

Topic是把数据分别存储到不同的分区中,也就是存放到不同的服务器中.

分区内部的数据是存放在多个文件中的,每个分区都有一定数量的.inde文件和.log文件,其中.index和.log文件,这两个文件组成一个`segment` 段,
这个段就存储着分区内的一部分数据,默认是1G.


### 3 与传统的消息系统相比,Kafka的消费模型有什么优点?

  kafka的消费模型是分布式的
  
  
### 4 Kafka如何实现分布式的数据存储与数据读取?

在Kafka文件存储中，同一个 topic下有多个不同partition，每个 partition 为一个目录,拥有自己的分区id,topic产生的数据分成多分存储在分区中,
每个分区都对应一台服务器,这样就把数据存放在了不同的服务器上,实现了分布式的数据存储.




### 5 Kafka为什么比RocketMQ支持的单机Partition要少?

### 6 为什么需要分区?也就是说主题只有一个分区,难道不行吗?


  如果只有一个分区,那么我们的topic产生的所有数据都会存放到一个broker中,一台服务器的内存是有限的,当数据足够大时,会造成服务器的内存不足,
就会影响到我们的服务,所以我们需要分区,把数据分成多分存储在不同的broker中,以减轻服务器的存储压力.

  同时这也会造成一个问题: 如果将数据分区存储,如果其中一台服务器挂掉,则会造成这部分数据不可用.<br>
解决方法: 对数据进行备份,也就是副本机制,将同一份数据备份,放到不同的服务器上.


### 7 日志为什么需要分段?

Kafka中的数据是以日志的形式存储的,Kafka作为消息中间件,只负责消息的临时存储,并不是永久存储,需要删除过期的数据.<br>
如果把所有的数据都存放在同一个文件,则删除过期的数据会很麻烦. <br>
因为文件有日期属性,删除过期的数据只需要根据文件的日期属性删除就行.

补充一下删除数据的两种方式:

        1 按照日期删除,如果只存储7天的日志,超过7天的则删除
        2 按照行数删除/按照文件的大小
    

### 8 Kafka是依靠什么机制保持高可靠的,高可用?

依靠副本机制

kafka中的多个服务端节点会对其他服务端节点的主题分区的log文件进行复制.

当集群中一个服务节点故障之后,这个故障的的服务器节点的所有请求都会被转移到其他正常的节点

kafka中的每个主题分区都有一个主副本(leader)和0个或多个副本,副本会同步主副本中的数据,当主副本不可用时,kafka会选择一个副本接替工作,
但并不是所有的副本都能担任主副本,需要满足两个条件:
  * 该副本保持和zookeeper的通信.
  * 该副本中同步主副本中的数据是最多的.

### 9 消息队列如何保证消息幂等?

### 10 让你自己设计个消息队列,你会怎么设计,会考虑那些方面?

* 1 该消息队列的使用场景? 是用于业务解耦,还是错峰流控等
* 2 选择基于消息的系统模型,是否需要broken(消息队列服务端),


**总结**

总而言之，消息队列不是万能的。对于需要强事务保证而且延迟敏感的，RPC是优于消息队列的。<br>
对于一些无关痛痒，或者对于别人非常重要但是对于自己不是那么关心的事情，可以利用消息队列去做。<br>
支持最终一致性的消息队列，能够用来处理延迟不那么敏感的“分布式事务”场景，而且相对于笨重的分布式事务，可能是更优的处理方式。<br>
当上下游系统处理能力存在差距的时候，利用消息队列做一个通用的“漏斗”。在下游有能力处理的时候，再进行分发。<br>
如果下游有很多系统关心你的系统发出的通知的时候，果断地使用消息队列吧。

*扩展*

* RPC :  远程过程调用协议RPC（Remote Procedure Call Protocol)

RPC是指远程过程调用，也就是说两台服务器A，B，一个应用部署在A服务器上，想要调用B服务器上应用提供的函数/方法，由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义和传达调用的数据。

常用的分布式RPC框架有：dubbo、motan、rpcx、gRPC、thrift等等。



### 11 kafka为什么那么快?

* kafka中的数据不支持修改.
* 由系统层面的优化,缓存读取有预读取机制





